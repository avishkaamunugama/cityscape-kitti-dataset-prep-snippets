{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop, resize and split CityScapes data folders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove car logo and bonnet in images and corner distortions in gt disparity maps\n",
    "2. Split into  2 half . Each of size 944x708. aspect ratio = 4/3\n",
    "3. Resize spit into 640x480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "conv_pics_count = 0\n",
    "root_dir = os.path.join(r\"D:\\Downloads\\DATASETS\\CITYSCAPES\\cityscape_weather\\original\\disparity\")\n",
    "splits_dir = os.path.join(r\"D:\\Downloads\\DATASETS\\CITYSCAPES\\cityscape_weather\\original\\out\\disparity\")\n",
    "\n",
    "number_of_files = len(os.listdir(root_dir))\n",
    "print(f\"Found {number_of_files} files.\")\n",
    "\n",
    "for path, subdirs, files in os.walk(root_dir):\n",
    "    for filename in files:\n",
    "\n",
    "        ext = os.path.splitext(filename)[-1].lower()\n",
    "\n",
    "        if ext=='.png':\n",
    "\n",
    "            conv_pics_count += 1\n",
    "            if ((conv_pics_count/number_of_files) * 100) % 10 == 0:\n",
    "                print(f\"Completed : {((conv_pics_count/number_of_files) * 100)}%\")\n",
    "            # Read the image\n",
    "            f = os.path.join(path, filename)\n",
    "            img = Image.open(f)\n",
    "\n",
    "            #prep\n",
    "            o_width,o_height = img.size\n",
    "\n",
    "            if o_width/o_height == 2:\n",
    "                if img.size != (2048,1024):\n",
    "                    img = img.resize((2048,1024))\n",
    "            else:\n",
    "                raise Exception(f\"Following image is of incompatible ratio. Please use images with aspect ratio of 2. \\n{os.path.join(path,filename)}\")\n",
    "\n",
    "            # to remove car logo and corner distortions in gt disparity maps\n",
    "            initial_crop = (1888,708)\n",
    "            left_margin = 112\n",
    "            top_margin = 78\n",
    "\n",
    "            width, height = initial_crop\n",
    "\n",
    "            #1. split into  2 half . Each of size 944x708. aspect ratio = 4/3\n",
    "            width_cutoff = width // 2\n",
    "            s1 = img.crop((left_margin,top_margin,width_cutoff + left_margin, height + top_margin))\n",
    "            s2 = img.crop((width_cutoff + left_margin,top_margin,width + left_margin,height + top_margin))\n",
    "\n",
    "            #2. resize spit into 640x480\n",
    "            s1 = s1.resize((640,480))\n",
    "            s2 = s2.resize((640,480))\n",
    "\n",
    "            # Save each half\n",
    "            s1.save(os.path.join(splits_dir, f\"{os.path.splitext(filename)[0]}_l.png\"), format=\"png\")\n",
    "            s2.save(os.path.join(splits_dir, f\"{os.path.splitext(filename)[0]}_r.png\"), format=\"png\")\n",
    "\n",
    "print(f\"Done. {conv_pics_count} files splitted.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate gt images with same name as input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "gt_dir = os.path.join(r'D:\\Downloads\\Resized_datasets\\1888x768\\640x480\\clear')\n",
    "input_dir = os.path.join(r'D:\\Downloads\\Resized_datasets\\1888x768\\640x480\\input')\n",
    "new_gt_dir = os.path.join(r'D:\\Downloads\\Resized_datasets\\1888x768\\640x480\\gt')\n",
    "\n",
    "gt_files_arr = []\n",
    "\n",
    "for path, subdirs, files in os.walk(gt_dir):\n",
    "    for filename in files:\n",
    "        ext = os.path.splitext(filename)[-1].lower()\n",
    "        if ext=='.png':\n",
    "            gt_files_arr.append(filename)\n",
    "\n",
    "\n",
    "print(f\"{len(gt_files_arr)} clear gt images found.\")\n",
    "\n",
    "input_files_arr = []\n",
    "\n",
    "for path, subdirs, files in os.walk(input_dir):\n",
    "    for filename in files:\n",
    "        ext = os.path.splitext(filename)[-1].lower()\n",
    "        if ext=='.png':\n",
    "            input_files_arr.append(filename)\n",
    "\n",
    "\n",
    "print(f\"{len(input_files_arr)} allweather input images found.\")\n",
    "\n",
    "def getImgId(filename):\n",
    "    f = filename.split('_')\n",
    "    \n",
    "    if len(f) < 3:\n",
    "        subf = f[0].split('-')\n",
    "        fileId = f\"{subf[0]}_{subf[1]}\".lower()\n",
    "    else:\n",
    "        fileId = f\"{f[0]}_{f[1]}_{f[2]}\".lower()\n",
    "    \n",
    "    fileType = str(f[-1]).lower()\n",
    "\n",
    "    return fileId, fileType\n",
    "\n",
    "found_imgs = []\n",
    "\n",
    "for input_img in input_files_arr:\n",
    "    for cl in gt_files_arr:\n",
    "        try:\n",
    "            if getImgId(input_img) == getImgId(cl):\n",
    "                shutil.copy(os.path.join(gt_dir, cl), os.path.join(new_gt_dir, input_img.lower()))\n",
    "                found_imgs.append(os.path.join(gt_dir, cl))\n",
    "                break\n",
    "        except IndexError:\n",
    "            print(input_img , \" : \", cl)\n",
    "\n",
    "    if (((len(found_imgs)/len(input_files_arr))*100) % 10) == 0:\n",
    "        print(str((len(found_imgs)/len(input_files_arr))*100) + \"% processed.\")\n",
    "        \n",
    "\n",
    "print(f\"Done. Found {len(found_imgs)} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate side-by-side images as in Pix2Pix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/phillipi/pix2pix#generating-pairs\n",
    "\n",
    "Create folder /path/to/data with subfolders A and B. A and B should each have their own subfolders train, val, test, etc. In /path/to/data/A/train, put training images in style A. In /path/to/data/B/train, put the corresponding images in style B. Repeat same for other data splits (val, test, etc).\n",
    "\n",
    "Corresponding images in a pair {A,B} must be the same size and have the same filename, e.g., /path/to/data/A/train/1.jpg is considered to correspond to /path/to/data/B/train/1.jpg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/phillipi/pix2pix.git\n",
    "\n",
    "# A denotes gt image\n",
    "# B inpute image\n",
    "# Make sure all images are of same size\n",
    "\n",
    "!python scripts/combine_A_and_B.py --fold_A /path/to/data/A --fold_B /path/to/data/B --fold_AB /path/to/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate txt with input-gt image pair names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "txt_file_path = 'clear_train.txt'\n",
    "gt_dir = r'disparity'\n",
    "input_dir = r'train/clear'\n",
    "\n",
    "gtArray = []\n",
    "\n",
    "for path, subdirs, files in os.walk(gt_dir):\n",
    "    for filename in files:\n",
    "        f = os.path.join(path, filename)\n",
    "        absPath = Path(f).as_posix()\n",
    "        gtArray.append(absPath)\n",
    "\n",
    "print(f'Found {len(gtArray)} gt images.')\n",
    "\n",
    "\n",
    "with open(txt_file_path, \"w\") as a:\n",
    "    for path, subdirs, files in os.walk(input_dir):\n",
    "        for filename in files:\n",
    "\n",
    "            gtFileName=''\n",
    "            for gt in gtArray:\n",
    "                if gt.split('/')[1].split('_disparity')[0] == filename.split('_leftImg8bit')[0]:\n",
    "                    gtFileName = gt\n",
    "                    break\n",
    "\n",
    "            if len(gtFileName) == 0:\n",
    "                raise Exception('Unable to find GT for ', os.path.join(path, filename))\n",
    "\n",
    "            f = os.path.join(path, filename)\n",
    "            absPath = Path(f).as_posix()\n",
    "\n",
    "            # print(str(absPath) + \",\" + str(gtFileName) + \"\\n\")\n",
    "\n",
    "            a.write(str(absPath) + \",\" + str(gtFileName) + \"\\n\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train/test/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "\n",
    "def main():\n",
    "    input_folder = r\"D:\\Downloads\\DATASETS\\CITYSCAPES\\cityscape_weather\\original\\out\\2. clear --- depth\\in\"\n",
    "    output_folder = r\"D:\\Downloads\\DATASETS\\CITYSCAPES\\cityscape_weather\\original\\out\\2. clear --- depth\\out\"\n",
    "\n",
    "    splitfolders.ratio(input_folder, output= output_folder,\n",
    "                        seed=42, ratio=(.875,.1,.025), group_prefix=None)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate (size,type,path) images in folder and cross-check with txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "fileName = 'all_weather_test.txt'\n",
    "root_dir = r'D:\\Downloads\\Resized_datasets\\640x480\\CITYSCAPE_768x768\\data'\n",
    "size = (640,480)\n",
    "\n",
    "lines=open(os.path.join(root_dir,fileName)).read().splitlines()\n",
    "lineCount = len(lines)\n",
    "iterator = 0\n",
    "\n",
    "for i in range(lineCount):\n",
    "\n",
    "    percent = ((i/lineCount) * 100)\n",
    "    if percent > 0 and percent%10 == 0:\n",
    "        print(str(percent)+'% . Checked ' +str(iterator)+ ' files.')\n",
    "\n",
    "    filePath = lines[i].split(',')[0]\n",
    "\n",
    "    file = Path(os.path.join(root_dir,filePath))\n",
    "\n",
    "    iterator+=1\n",
    "\n",
    "    if file.is_file():\n",
    "        im = Image.open(os.path.join(root_dir,filePath))\n",
    "        width, height = im.size\n",
    "\n",
    "        if width != size[0] and height != size[1]:\n",
    "            raise Exception(os.path.join(root_dir,filePath) , \" is wrong size\")\n",
    "    else:\n",
    "        raise Exception(os.path.join(root_dir,filePath) , \" does not exist\")\n",
    "\n",
    "print(\"All file checked! Checked \" +str(iterator)+ \" files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate (size,type) all images in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "root_dir = r'D:\\Downloads\\DATASETS\\CITYSCAPES\\cityscape_weather\\original\\input'\n",
    "size = (2048,1024)\n",
    "iterator = 0\n",
    "\n",
    "number_of_files = len(os.listdir(root_dir))\n",
    "print(f\"Found {number_of_files} files.\")\n",
    "\n",
    "for path, subdirs, files in os.walk(root_dir):\n",
    "    for filename in files:\n",
    "        ext = os.path.splitext(filename)[-1].lower()\n",
    "        if ext=='.png':\n",
    "\n",
    "            iterator += 1\n",
    "            percent = ((iterator/number_of_files) * 100)\n",
    "            if percent > 0 and percent%10 == 0:\n",
    "                print(str(percent)+'% . Checked ' +str(iterator)+ ' files.')\n",
    "\n",
    "            im = Image.open(os.path.join(path,filename))\n",
    "            width, height = im.size\n",
    "            if im.size != size:\n",
    "                raise Exception(os.path.join(path,filename) , \" is wrong size\")\n",
    "        else:\n",
    "            raise Exception(os.path.join(path,filename) , \" is not an image\")\n",
    "\n",
    "print(\"All file checked! Checked \" +str(iterator)+ \" files.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate (size,type,path) and move input and gt files into folders as in txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "fileName = 'all_weather_train.txt'\n",
    "root_dir = r'D:\\Downloads\\DATASETS\\CITYSCAPES\\cityscape_weather\\original\\out\\3. weather --- depth'\n",
    "new_dir = r'D:\\Downloads\\DATASETS\\CITYSCAPES\\cityscape_weather\\original\\out\\3. weather --- depth\\trainB'\n",
    "size = (640,480)\n",
    "\n",
    "lines=open(os.path.join(root_dir,fileName)).read().splitlines()\n",
    "lineCount = len(lines)\n",
    "\n",
    "def validateAndMove(filePath):\n",
    "    \n",
    "    global iterator\n",
    "    iterator+=1\n",
    "    file = Path(os.path.join(root_dir,filePath))\n",
    "\n",
    "    if file.is_file():\n",
    "        im = Image.open(os.path.join(root_dir,filePath))\n",
    "        width, height = im.size\n",
    "\n",
    "        if width != size[0] and height != size[1]:\n",
    "            raise Exception(os.path.join(root_dir,filePath) , \" is wrong size\")\n",
    "\n",
    "        im.close()\n",
    "\n",
    "        os.rename(os.path.join(root_dir,filePath), os.path.join(new_dir, filePath.split('/')[-1]))\n",
    "        # print(str(os.path.join(root_dir,filePath)) + '\\n' + str(os.path.join(new_dir, filePath.split('/')[-1])))\n",
    "\n",
    "    else:\n",
    "        raise Exception(os.path.join(root_dir,filePath) , \" does not exist\")\n",
    "\n",
    "iterator = 0\n",
    "\n",
    "for i in range(lineCount):\n",
    "\n",
    "    percent = ((i/lineCount) * 100)\n",
    "    if percent > 0 and percent%10 == 0:\n",
    "        print(str(percent)+'% . Checked ' +str(iterator)+ ' files.')\n",
    "\n",
    "    filePaths = lines[i].split(',')\n",
    "\n",
    "    validateAndMove(filePaths[0])\n",
    "\n",
    "    # validateAndMove(filePaths[1], \"disparity\")\n",
    "\n",
    "print(\"All file checked! Checked \" +str(iterator)+ \" files.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write all dataset filenames to txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "txt_file_path = \"rain.txt\"\n",
    "data_dir = r'./rain'\n",
    "\n",
    "with open(txt_file_path, \"w\") as a:\n",
    "    for path, subdirs, files in os.walk(data_dir):\n",
    "        for filename in files:\n",
    "            f = os.path.join(path, filename)\n",
    "            absPath = Path(f).as_posix()\n",
    "            a.write(str(absPath) + \"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly move a number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "\n",
    "to_be_moved = random.sample(glob.glob(\"foggy/*.png\"), 300)\n",
    "\n",
    "for f in enumerate(to_be_moved):\n",
    "    shutil.move(f[1], \"val/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KITTI Depth map impainting using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Matlab code https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html\n",
    "#\n",
    "#\n",
    "# Python port of depth filling code from NYU toolbox\n",
    "# Speed needs to be improved\n",
    "#\n",
    "# Uses 'pypardiso' solver \n",
    "#\n",
    "import scipy\n",
    "import skimage\n",
    "import skimage.color\n",
    "import numpy as np\n",
    "from pypardiso import spsolve\n",
    "from PIL import Image\n",
    "\n",
    "#\n",
    "# fill_depth_colorization.m\n",
    "# Preprocesses the kinect depth image using a gray scale version of the\n",
    "# RGB image as a weighting for the smoothing. This code is a slight\n",
    "# adaptation of Anat Levin's colorization code:\n",
    "#\n",
    "# See: www.cs.huji.ac.il/~yweiss/Colorization/\n",
    "#\n",
    "# Args:\n",
    "#  imgRgb - HxWx3 matrix, the rgb image for the current frame. This must\n",
    "#      be between 0 and 1.\n",
    "#  imgDepth - HxW matrix, the depth image for the current frame in\n",
    "#       absolute (meters) space.\n",
    "#  alpha - a penalty value between 0 and 1 for the current depth values.\n",
    "\n",
    "def fill_depth_colorization(imgRgb=None, imgDepthInput=None, alpha=1):\n",
    "\timgIsNoise = imgDepthInput == 0\n",
    "\tmaxImgAbsDepth = np.max(imgDepthInput)\n",
    "\timgDepth = imgDepthInput / maxImgAbsDepth\n",
    "\timgDepth[imgDepth > 1] = 1\n",
    "\t(H, W) = imgDepth.shape\n",
    "\tnumPix = H * W\n",
    "\tindsM = np.arange(numPix).reshape((W, H)).transpose()\n",
    "\tknownValMask = (imgIsNoise == False).astype(int)\n",
    "\tgrayImg = skimage.color.rgb2gray(imgRgb)\n",
    "\twinRad = 1\n",
    "\tlen_ = 0\n",
    "\tabsImgNdx = 0\n",
    "\tlen_window = (2 * winRad + 1) ** 2\n",
    "\tlen_zeros = numPix * len_window\n",
    "\n",
    "\tcols = np.zeros(len_zeros) - 1\n",
    "\trows = np.zeros(len_zeros) - 1\n",
    "\tvals = np.zeros(len_zeros) - 1\n",
    "\tgvals = np.zeros(len_window) - 1\n",
    "\n",
    "\tfor j in range(W):\n",
    "\t\tfor i in range(H):\n",
    "\t\t\tnWin = 0\n",
    "\t\t\tfor ii in range(max(0, i - winRad), min(i + winRad + 1, H)):\n",
    "\t\t\t\tfor jj in range(max(0, j - winRad), min(j + winRad + 1, W)):\n",
    "\t\t\t\t\tif ii == i and jj == j:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\trows[len_] = absImgNdx\n",
    "\t\t\t\t\tcols[len_] = indsM[ii, jj]\n",
    "\t\t\t\t\tgvals[nWin] = grayImg[ii, jj]\n",
    "\n",
    "\t\t\t\t\tlen_ = len_ + 1\n",
    "\t\t\t\t\tnWin = nWin + 1\n",
    "\n",
    "\t\t\tcurVal = grayImg[i, j]\n",
    "\t\t\tgvals[nWin] = curVal\n",
    "\t\t\tc_var = np.mean((gvals[:nWin + 1] - np.mean(gvals[:nWin+ 1])) ** 2)\n",
    "\n",
    "\t\t\tcsig = c_var * 0.6\n",
    "\t\t\tmgv = np.min((gvals[:nWin] - curVal) ** 2)\n",
    "\t\t\tif csig < -mgv / np.log(0.01):\n",
    "\t\t\t\tcsig = -mgv / np.log(0.01)\n",
    "\n",
    "\t\t\tif csig < 2e-06:\n",
    "\t\t\t\tcsig = 2e-06\n",
    "\n",
    "\t\t\tgvals[:nWin] = np.exp(-(gvals[:nWin] - curVal) ** 2 / csig)\n",
    "\t\t\tgvals[:nWin] = gvals[:nWin] / sum(gvals[:nWin])\n",
    "\t\t\tvals[len_ - nWin:len_] = -gvals[:nWin]\n",
    "\n",
    "\t  \t\t# Now the self-reference (along the diagonal).\n",
    "\t\t\trows[len_] = absImgNdx\n",
    "\t\t\tcols[len_] = absImgNdx\n",
    "\t\t\tvals[len_] = 1  # sum(gvals(1:nWin))\n",
    "\n",
    "\t\t\tlen_ = len_ + 1\n",
    "\t\t\tabsImgNdx = absImgNdx + 1\n",
    "\n",
    "\tvals = vals[:len_]\n",
    "\tcols = cols[:len_]\n",
    "\trows = rows[:len_]\n",
    "\tA = scipy.sparse.csr_matrix((vals, (rows, cols)), (numPix, numPix))\n",
    "\n",
    "\trows = np.arange(0, numPix)\n",
    "\tcols = np.arange(0, numPix)\n",
    "\tvals = (knownValMask * alpha).transpose().reshape(numPix)\n",
    "\tG = scipy.sparse.csr_matrix((vals, (rows, cols)), (numPix, numPix))\n",
    "\n",
    "\tA = A + G\n",
    "\tb = np.multiply(vals.reshape(numPix), imgDepth.flatten('F'))\n",
    "\n",
    "\t#print ('Solving system..')\n",
    "\n",
    "\tnew_vals = spsolve(A, b)\n",
    "\tnew_vals = np.reshape(new_vals, (H, W), 'F')\n",
    "\n",
    "\t#print ('Done.')\n",
    "\n",
    "\tdenoisedDepthImg = new_vals * maxImgAbsDepth\n",
    "    \n",
    "\toutput = denoisedDepthImg.reshape((H, W)).astype('float32')\n",
    "\n",
    "\toutput = np.multiply(output, (1-knownValMask)) + imgDepthInput\n",
    "    \n",
    "\treturn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "train_filename = \"train.txt\"\n",
    "root_dir = r\"C:\\Users\\avishka\\Downloads\\Depth processing\" # Source Folder\n",
    "dstpath = r\"C:\\Users\\avishka\\Downloads\\Depth processing\\output\" # Destination Folder\n",
    "\n",
    "train_list = os.path.join(root_dir ,train_filename)\n",
    "\n",
    "with open(train_list) as f:\n",
    "    contents = f.readlines()\n",
    "    input_names = [i.strip() for i in contents]\n",
    "       \n",
    "       \n",
    "i = 0\n",
    "failed = []\n",
    "\n",
    "for img_path in input_names:\n",
    "    clear_path = img_path.strip().replace('input','gt_clear')\n",
    "    depth_path = img_path.strip().replace('input','gt_disparity')\n",
    "    \n",
    "    clear_img = cv2.imread(os.path.join(root_dir,clear_path))\n",
    "    clear_img = cv2.cvtColor(clear_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    depth_img = cv2.imread(os.path.join(root_dir,depth_path))\n",
    "    depth_img = cv2.cvtColor(depth_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    processed_img = fill_depth_colorization(imgRgb=clear_img, imgDepthInput=depth_img)\n",
    "    \n",
    "    try:\n",
    "        dstPath = os.path.join(dstpath,img_path)\n",
    "        cv2.imwrite(dstPath,processed_img)\n",
    "    except:\n",
    "        print(\"Save Failed - \",str(img_path))\n",
    "        failed.append(img_path)\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "    if i%100 == 0:\n",
    "        print(\"completed {} images.\".format(i))\n",
    "    \n",
    "print(\"All Complete.{} images processed.\".format(i))\n",
    "print(\"{} images failed to process.\".format(len(failed)))\n",
    "print(failed)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
